<resources>
{% for host in groups['nodes'] %}
      <primitive class="stonith" id="stonith_{{ host }}" type="fence_ipmilan">
        <meta_attributes id="stonith_{{ host }}-meta_attributes">
          <nvpair id="stonith_{{ host }}-meta_attributes-target-role" name="target-role" value="Started"/>
        </meta_attributes>
        <operations id="stonith_{{ host }}-operations">
          <op id="stonith_{{ host }}-op-monitor-1800" interval="1800" name="monitor" timeout="30"/>
          <op id="stonith_{{ host }}-op-start-0" interval="0" name="start" on-fail="restart" start-delay="5" timeout="120"/>
          <op id="stonith_{{ host }}-op-stop-0" interval="0" name="stop" timeout="60"/>
        </operations>
        <instance_attributes id="stonith_{{ host }}-instance_attributes">
          <nvpair id="stonith_{{ host }}-instance_attributes-pcmk_host_list" name="pcmk_host_list" value="{{ host }}"/>
          <nvpair id="stonith_{{ host }}-instance_attributes-ipaddr" name="ipaddr" value="{{ network.control.address }}.{{ nodes_ip_ipmi[host] }}"/>
          <nvpair id="stonith_{{ host }}-instance_attributes-login" name="login" value="{{ ipmi.login }}"/>
          <nvpair id="stonith_{{ host }}-instance_attributes-passwd" name="passwd" value="{{ ipmi.password }}"/>
          <nvpair id="stonith_{{ host }}-instance_attributes-lanplus" name="lanplus" value="true"/>
          <nvpair id="stonith_{{ host }}-instance_attributes-auth" name="auth" value="password"/>
          <nvpair id="stonith_{{ host }}-instance_attributes-pcmk_reboot_action" name="pcmk_reboot_action" value="reboot"/>
        </instance_attributes>
      </primitive>
{% endfor %}
{% if pdu_fencing is defined and pdu_fencing%}
{% for row in pdu_fencing %}
{% if row.pdu is defined and row.pdu and row.nodes is defined and row.nodes %}
{% for key, value in row.nodes.iteritems() %}
{% for ip in row.pdu %}
      <primitive class="stonith" id="fence_{{ key }}_pdu{{ ip }}_on" type="fence_apc_snmp">
        <meta_attributes id="fence_{{ key }}_pdu{{ ip }}_on-meta_attributes">
          <nvpair id="fence_{{ key }}_pdu{{ ip }}_on-meta_attributes-target-role" name="target-role" value="Started"/>
        </meta_attributes>
        <instance_attributes id="fence_{{ key }}_pdu{{ ip }}_on-instance_attributes">
          <nvpair id="fence_{{ key }}_pdu{{ ip }}_on-instance_attributes-ipaddr" name="ipaddr" value="{{ network.control.address }}.{{ ip }}"/>
          <nvpair id="fence_{{ key }}_pdu{{ ip }}_on-instance_attributes-pcmk_reboot_action" name="pcmk_reboot_action" value="on"/>
          <nvpair id="fence_{{ key }}_pdu{{ ip }}_on-instance_attributes-port" name="port" value="{{ value }}"/>
          <nvpair id="fence_{{ key }}_pdu{{ ip }}_on-instance_attributes-pcmk_host_list" name="pcmk_host_list" value="{{ key }}"/>
        </instance_attributes>
        <operations>
          <op id="fence_{{ key }}_pdu{{ ip }}_on-monitor-1800" interval="1800" name="monitor" timeout="30"/>
          <op id="fence_{{ key }}_pdu{{ ip }}_on-op-start-0" interval="0" name="start" on-fail="restart" start-delay="5" timeout="120"/>
          <op id="fence_{{ key }}_pdu{{ ip }}_on-op-stop-0" interval="0" name="stop" timeout="60"/>
        </operations>
      </primitive>
      <primitive class="stonith" id="fence_{{ key }}_pdu{{ ip }}_off" type="fence_apc_snmp">
        <meta_attributes id="fence_{{ key }}_pdu{{ ip }}_off-meta_attributes">
          <nvpair id="fence_{{ key }}_pdu{{ ip }}_off-meta_attributes-target-role" name="target-role" value="Started"/>
        </meta_attributes>
        <instance_attributes id="fence_{{ key }}_pdu{{ ip }}_off-instance_attributes">
          <nvpair id="fence_{{ key }}_pdu{{ ip }}_off-instance_attributes-ipaddr" name="ipaddr" value="{{ network.control.address }}.{{ ip }}"/>
          <nvpair id="fence_{{ key }}_pdu{{ ip }}_off-instance_attributes-pcmk_reboot_action" name="pcmk_reboot_action" value="off"/>
          <nvpair id="fence_{{ key }}_pdu{{ ip }}_off-instance_attributes-port" name="port" value="{{ value }}"/>
          <nvpair id="fence_{{ key }}_pdu{{ ip }}_off-instance_attributes-pcmk_host_list" name="pcmk_host_list" value="{{ key }}"/>
         {% if loop.last %}<nvpair id="fence_{{ key }}_pdu{{ ip }}_off-instance_attributes-power_wait" name="power_wait" value="5"/>{% endif %}
        </instance_attributes>
        <operations>
          <op id="fence_{{ key }}_pdu{{ ip }}_off-monitor-1800" interval="1800" name="monitor" timeout="30"/>
          <op id="fence_{{ key }}_pdu{{ ip }}_off-op-start-0" interval="0" name="start" on-fail="restart" start-delay="5" timeout="120"/>
          <op id="fence_{{ key }}_pdu{{ ip }}_off-op-stop-0" interval="0" name="stop" timeout="60"/>
        </operations>
      </primitive>
{% endfor %}
{% endfor %}
{% endif %}
{% endfor %}
{% endif %}
      <clone id="glusterd">
        <meta_attributes id="glusterd-meta_attributes">
          <nvpair id="glusterd-meta_attributes-target-role" name="target-role" value="Started"/>
          <nvpair id="glusterd-meta_attributes-interleave" name="interleave" value="true"/>
        </meta_attributes>
        <primitive class="ocf" id="demon" provider="heartbeat" type="glusterd">
          <operations id="demon-operations">
            <op id="demon-op-monitor-60" interval="60" name="monitor" timeout="20"/>
          </operations>
        </primitive>
      </clone>
      <clone id="gluster_volume">
        <meta_attributes id="gluster_volume-meta_attributes">
          <nvpair id="gluster_volume-meta_attributes-target-role" name="target-role" value="Started"/>
          <nvpair id="gluster_volume-meta_attributes-interleave" name="interleave" value="true"/>
        </meta_attributes>
        <primitive class="ocf" id="volume_demon" provider="heartbeat" type="volume">
          <operations id="volume_demon-operations">
            <op id="volume_demon-op-monitor-60" interval="60" name="monitor" timeout="20"/>
          </operations>
          <instance_attributes id="volume_demon-instance_attributes">
            <nvpair id="volume_demon-instance_attributes-volname" name="volname" value="{{ gluster.volume }}"/>
          </instance_attributes>
        </primitive>
      </clone>
      <clone id="mount_gluster">
        <meta_attributes id="mount_gluster-meta_attributes">
          <nvpair id="mount_gluster-meta_attributes-target-role" name="target-role" value="Started"/>
          <nvpair id="mount_gluster-meta_attributes-interleave" name="interleave" value="true"/>
        </meta_attributes>
        <primitive class="ocf" id="gluster_dest" provider="heartbeat" type="Filesystem">
          <operations id="gluster_dest-operations">
            <op id="gluster_dest-op-monitor-40" interval="40" name="monitor" on-fail="restart" timeout="40"/>
          </operations>
          <instance_attributes id="gluster_dest-instance_attributes">
            <nvpair id="gluster_dest-instance_attributes-device" name="device" value="{{ extra_settings.path_to_config }}/glusterd/vols/{{ gluster.volume }}/{{ gluster.volume }}-fuse.vol"/>
            <nvpair id="gluster_dest-instance_attributes-directory" name="directory" value="{{ gluster.mount_point }}"/>
            <nvpair id="gluster_dest-instance_attributes-fstype" name="fstype" value="glusterfs"/>
            <nvpair id="gluster_dest-instance_attributes-options" name="options" value="defaults,_netdev"/>
            <nvpair id="gluster_dest-instance_attributes-force_clones" name="force_clones" value="true"/>
          </instance_attributes>
          <meta_attributes id="gluster_dest-meta_attributes">
            <nvpair id="gluster_dest-meta_attributes-target-role" name="target-role" value="Started"/>
          </meta_attributes>
        </primitive>
      </clone>
      <template class="ocf" id="vm_template" provider="heartbeat" type="VirtualDomain">
        <meta_attributes id="vm_template-meta_attributes">
          <nvpair id="vm_template-meta_attributes-target-role" name="target-role" value="Started"/>
          <nvpair id="vm_template-meta_attributes-allow-migrate" name="allow-migrate" value="true"/>
        </meta_attributes>
        <operations id="vm_template-operations">
          <op id="vm_template-op-monitor-40" interval="40" name="monitor" timeout="30"/>
          <op id="vm_template-op-start-0-0" interval="0" name="start" timeout="120"/>
          <op id="vm_template-op-stop-0" interval="0" name="stop" timeout="120"/>
          <op id="vm_template-op-migrate_from-0" interval="0" name="migrate_from" timeout="120"/>
          <op id="vm_template-op-migrate_to-0" interval="0" name="migrate_to" timeout="120"/>
        </operations>
        <instance_attributes id="vm_template-instance_attributes">
          <nvpair id="vm_template-instance_attributes-hypervisor" name="hypervisor" value="qemu:///system"/>
          <nvpair id="vm_template-instance_attributes-migration_transport" name="migration_transport" value="tcp"/>
          <nvpair id="vm_template-instance_attributes-autoset_utilization_cpu" name="autoset_utilization_cpu" value="false"/>
          <nvpair id="vm_template-instance_attributes-autoset_utilization_hv_memory" name="autoset_utilization_hv_memory" value="false"/>
        </instance_attributes>
      </template>
      <template class="ocf" id="dummy_template" provider="pacemaker" type="Dummy">
        <meta_attributes id="dummy_template-meta_attributes">
          <nvpair id="dummy_template-meta_attributes-target-role" name="target-role" value="Started"/>
        </meta_attributes>
        <operations id="dummy_template-operations">
          <op id="dummy_template-op-monitor-10" interval="10" name="monitor" timeout="20"/>
        </operations>
      </template>
      <clone id="{{ resource_id.ald_client }}">
        <meta_attributes id="{{ resource_id.ald_client }}-meta_attributes">
          <nvpair id="{{ resource_id.ald_client }}-meta_attributes-target-role" name="target-role" value="Started"/>
          <nvpair id="{{ resource_id.ald_client }}-meta_attributes-interleave" name="interleave" value="true"/>
        </meta_attributes>
        <group id="ald_client">
          <primitive class="lsb" id="krb5-kdc_rsc" type="krb5-kdc">
            <operations id="krb5-kdc_rsc-operations">
              <op id="krb5-kdc_rsc-op-monitor-50" interval="50" name="monitor" timeout="15"/>
            </operations>
          </primitive>
          <primitive class="lsb" id="krb5-prop_rsc" type="krb5-prop">
            <operations id="krb5-prop_rsc-operations">
              <op id="krb5-prop_rsc-op-monitor-50" interval="50" name="monitor" timeout="15"/>
            </operations>
          </primitive>
          <primitive class="lsb" id="nscd_rcs" type="nscd">
            <operations id="nscd_rcs-operations">
              <op id="nscd_rcs-op-monitor-50" interval="50" name="monitor" timeout="15"/>
            </operations>
          </primitive>
          <primitive class="lsb" id="nslcd_rcs" type="nslcd">
            <operations id="nslcd_rcs-operations">
              <op id="nslcd_rcs-op-monitor-50" interval="50" name="monitor" timeout="15"/>
            </operations>
          </primitive>
          <primitive class="lsb" id="aldcd_rcs" type="aldcd">
            <operations id="aldcd_rcs-operations">
              <op id="aldcd_rcs-op-monitor-50" interval="50" name="monitor" timeout="15"/>
            </operations>
          </primitive>
          <primitive class="lsb" id="apache" type="apache2">
            <operations id="apache-operations">
              <op id="apache-op-monitor-50" interval="50" name="monitor" timeout="30"/>
            </operations>
          </primitive>
        </group>
      </clone>
      <group id="{{ resource_id.ald_server }}">
        <primitive class="ocf" id="hac_cntrl_ip" provider="heartbeat" type="IPaddr2">
          <operations id="hac_cntrl_ip-operations">
            <op id="hac_cntrl_ip-op-monitor-100" interval="100" name="monitor" timeout="20"/>
            <op id="hac_cntrl_ip-op-start-0" interval="0" name="start" timeout="30"/>
            <op id="hac_cntrl_ip-op-stop-0" interval="0" name="stop" timeout="20"/>
          </operations>
          <instance_attributes id="hac_cntrl_ip-instance_attributes">
            <nvpair id="hac_cntrl_ip-instance_attributes-ip" name="ip" value="{{ network.public.address }}.{{ hac_cntrl.ip }}"/>
            <nvpair id="hac_cntrl_ip-instance_attributes-cidr_netmask" name="cidr_netmask" value="{{hac_cntrl.cidr_netmask}}"/>
        </instance_attributes>
        </primitive>
        <meta_attributes id="{{ resource_id.ald_server }}-meta_attributes">
          <nvpair id="{{ resource_id.ald_server }}-meta_attributes-target-role" name="target-role" value="Started"/>
          <nvpair id="{{ resource_id.ald_server }}-meta_attributes-resource-stickiness" name="resource-stickiness" value="10000"/>
        </meta_attributes>
        <primitive class="lsb" id="krb5-admin-server_rsc" type="krb5-admin-server">
          <operations id="krb5-admin-server_rsc-operations">
            <op id="krb5-admin-server_rsc-op-monitor-50" interval="50" name="monitor" timeout="15"/>
            <op id="krb5-admin-server_rsc-op-start-0" interval="0" name="start" timeout="60"/>
            <op id="krb5-admin-server_rsc-op-stop-0" interval="0" name="stop" timeout="60"/>
          </operations>
        </primitive>
        <primitive class="ocf" id="ldap_db_mount" provider="heartbeat" type="Filesystem">
          <operations id="ldap_db_mount-operations">
            <op id="ldap_db_mount-op-monitor-60" interval="60" name="monitor" timeout="40"/>
            <op id="ldap_db_mount-op-start-0" interval="0" name="start" timeout="60"/>
            <op id="ldap_db_mount-op-stop-0" interval="0" name="stop" timeout="60"/>
          </operations>
          <instance_attributes id="ldap_db_mount-instance_attributes">
            <nvpair id="ldap_db_mount-instance_attributes-device" name="device" value="{{ gluster.mount_point }}/ldap"/>
            <nvpair id="ldap_db_mount-instance_attributes-directory" name="directory" value="/var/lib/ldap"/>
            <nvpair id="ldap_db_mount-instance_attributes-fstype" name="fstype" value="none"/>
            <nvpair id="ldap_db_mount-instance_attributes-options" name="options" value="bind"/>
          </instance_attributes>
        </primitive>
        <primitive class="lsb" id="slapd_rsc" type="slapd">
          <operations id="slapd_rsc-operations">
            <op id="slapd_rsc-op-monitor-50" interval="50" name="monitor" timeout="15"/>
            <op id="slapd_rsc-op-start-0" interval="0" name="start" timeout="60"/>
            <op id="slapd_rsc-op-stop-0" interval="0" name="stop" timeout="60"/>
          </operations>
        </primitive>
        <primitive class="lsb" id="aldd_rsc" type="aldd">
          <operations id="aldd_rsc-operations">
            <op id="aldd_rsc-op-monitor-50" interval="50" name="monitor" timeout="15"/>
          </operations>
        </primitive>
      </group>
      <clone id="rdp_server_clone">
        <meta_attributes id="rdp_server_clone-meta_attributes">
          <nvpair id="rdp_server_clone-meta_attributes-target-role" name="target-role" value="Started"/>
          <nvpair id="rdp_server_clone-meta_attributes-interleave" name="interleave" value="true"/>
        </meta_attributes>
        <primitive class="lsb" id="rdp_server" type="xrdp">
          <operations id="rdp_server-operations">
            <op id="rdp_server-op-monitor-80" interval="80" name="monitor" timeout="15"/>
          </operations>
        </primitive>
      </clone>
      <clone id="ald_backup_timetable">
        <meta_attributes id="ald_backup_timetable-meta_attributes">
          <nvpair id="ald_backup_timetable-meta_attributes-target-role" name="target-role" value="Started"/>
          <nvpair id="ald_backup_timetable-meta_attributes-interleave" name="interleave" value="true"/>
        </meta_attributes>
        <primitive class="ocf" id="ald_backup_cron_task" provider="heartbeat" type="symlink">
          <operations id="ald_backup_cron_task-operations">
            <op id="ald_backup_cron_task-op-monitor-60" interval="60" name="monitor" timeout="15"/>
          </operations>
          <instance_attributes id="ald_backup_cron_task-instance_attributes">
            <nvpair id="ald_backup_cron_task-instance_attributes-link" name="link" value="/etc/cron.d/ald_backup"/>
            <nvpair id="ald_backup_cron_task-instance_attributes-target" name="target" value="{{ dirs.path_to_cron_file }}"/>
          </instance_attributes>
        </primitive>
      </clone>
</resources>
